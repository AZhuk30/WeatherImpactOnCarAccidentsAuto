name: Daily Data Update Pipeline
on:
  schedule:
    # Runs daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      date_range:
        description: 'Number of days to fetch'
        required: false
        default: '30'
jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    # 1. Checkout repository
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    # 2. Set up Python
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # 3. Install dependencies
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    # 4. Create data directories
    - name: Create data directories
      run: |
        mkdir -p data/processed
        mkdir -p data/raw
        mkdir -p data/logs
    
    # 4.5. Clear API cache and old data
    - name: Clear cache and old data
      run: |
        echo "Clearing any cached API data..."
        rm -f .cache.sqlite
        rm -rf __pycache__
        rm -rf src/__pycache__
        find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
        echo "Clearing old raw data files..."
        rm -f data/raw/*.csv
        echo "Cache cleared successfully"
    
    # 5. Run ETL Pipeline
    - name: Run ETL Pipeline
      run: |
        echo "Running ETL pipeline..."
        python run_pipeline.py --days ${{ github.event.inputs.date_range || '30' }}
    
    # 6. Verify data files were created
    - name: Verify data files
      run: |
        echo "Checking generated files:"
        ls -la data/processed/
        echo ""
        echo "Weather file size:"
        wc -l data/processed/weather_master.csv || echo "Weather file not found"
        echo ""
        echo "Collisions file size:"
        wc -l data/processed/collisions_master.csv || echo "Collisions file not found"
    

    
    # 7. Commit updated data files
    - name: Commit updated data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add the processed CSV files
        git add data/processed/*.csv
        
        # Get current timestamp
        TIMESTAMP=$(date '+%Y-%m-%d %H:%M UTC')
        
        # Check if there are changes
        if git diff --staged --quiet; then
          echo "No data changes detected - making keep-alive commit"
          git commit --allow-empty -m "ðŸ¤– Keep-alive: Daily check completed - $TIMESTAMP"
        else
          echo "Data files updated - committing changes"
          git commit -m "ðŸ¤– Auto-update: Data refresh $TIMESTAMP"
        fi
        
        # Always push
        echo "Pushing to GitHub..."
        git push
